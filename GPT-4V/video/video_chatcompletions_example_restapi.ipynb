{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759f9ec0",
   "metadata": {},
   "source": [
    "# REST API Video Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0cfcba",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Conducting Q&A with video inputs in GPT-4V.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbbcb1f",
   "metadata": {},
   "source": [
    "## Time\n",
    "\n",
    "You should expect to spend 5-10 minutes running this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13636fdc",
   "metadata": {},
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232525c",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ab502",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d4a0f",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "You need to set a series of configurations such as GPT-4V_DEPLOYMENT_NAME, OPENAI_API_BASE, OPENAI_API_VERSION, VISION_API_ENDPOINT.\n",
    "\n",
    "Add \"OPENAI_API_KEY\" and \"VISION_API_KEY\" as variable name and \\<Your API Key Value\\> and \\<Your VISION Key Value\\> as variable value in the environment variables.\n",
    " <br>\n",
    "      \n",
    "      WINDOWS Users: \n",
    "         setx OPENAI_API_KEY \"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "         setx VISION_API_KEY \"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "\n",
    "      MACOS/LINUX Users: \n",
    "         export OPENAI_API_KEY=\"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "         export VISION_API_KEY=\"REPLACE_WITH_YOUR_KEY_VALUE_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50667cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa50a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "deployment_name: str = os.getenv(\"GPT-4V_DEPLOYMENT_NAME\")\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai_api_base: str = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai_api_key: str = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Currently OPENAI API have the following versions available: 2022-12-01.\n",
    "# All versions follow the YYYY-MM-DD date structure.\n",
    "openai_api_version: str = os.getenv(\"OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57086a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the deployment name\n",
    "deployment_name: str = os.getenv(\"GPT-4V_DEPLOYMENT_NAME\")\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai_api_base: str = os.getenv(\"OPENAI_API_BASE\")\n",
    "# Currently OPENAI API have the following versions available: 2022-12-01.\n",
    "# All versions follow the YYYY-MM-DD date structure.\n",
    "openai_api_version: str = os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "# The base URL for your vision resource endpoint, e.g. \"https://<your-resource-name>.cognitiveservices.azure.com\"\n",
    "vision_api_endpoint: str = os.getenv(\"VISION_API_ENDPOINT\")\n",
    "\n",
    "# Insert your video SAS URL, e.g. https://<your-storage-account-name>.blob.core.windows.net/<your-container-name>/<your-video-name>?<SAS-token>\n",
    "video_SAS_url: str = \"https://gpt4vsamples.blob.core.windows.net/videos/Microsoft%20Copilot%20Short.mp4\"\n",
    "# This index name must be unique\n",
    "# It must start with alphanumeric, can contain hyphens but they must be followed by alphanumeric (no consecutive hyphens or trailing hyphen).\n",
    "# It must be 24 characters or less\n",
    "video_index_name: str = \"copilot-video-demo-index\"\n",
    "# This video ID must be unique\n",
    "video_id: str = \"copilot-video-1\"\n",
    "\n",
    "should_cleanup: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0f8ef",
   "metadata": {},
   "source": [
    "## Connect to your project\n",
    "To start with let us create a config file with your project details. This file can be used in this sample or other samples to connect to your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3d52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "config = {\n",
    "    \"GPT-4V_DEPLOYMENT_NAME\": deployment_name,\n",
    "    \"OPENAI_API_BASE\": openai_api_base,\n",
    "    \"OPENAI_API_VERSION\": openai_api_version,\n",
    "    \"VISION_API_ENDPOINT\": vision_api_endpoint,\n",
    "}\n",
    "\n",
    "p = Path(\"../config.json\")\n",
    "\n",
    "with p.open(mode=\"w\") as file:\n",
    "    file.write(json.dumps(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b60b2a",
   "metadata": {},
   "source": [
    "## Run this Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd85fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(str(parent_dir))\n",
    "from shared_functions import call_GPT4V_video, process_video_indexing\n",
    "\n",
    "# Setting up the vision resource key\n",
    "vision_api_key =\"4660b804230a4cde925f324b813126f3\"      #os.getenv(\"VISION_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca1eb38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4660b804230a4cde925f324b813126f3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907668a",
   "metadata": {},
   "source": [
    "### Create Video Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "704ffbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 {\"name\":\"copilot-video-demo-index\",\"userData\":{},\"features\":[{\"name\":\"vision\",\"modelVersion\":\"2023-05-31\",\"domain\":\"surveillance\"},{\"name\":\"speech\",\"modelVersion\":\"2023-06-30\",\"domain\":\"generic\"}],\"eTag\":\"\\\"ab198b40b10042ce8f990af3fb411e52\\\"\",\"createdDateTime\":\"2024-01-08T12:42:19.9841630Z\",\"lastModifiedDateTime\":\"2024-01-08T12:42:19.9841630Z\"}\n",
      "202 {\"name\":\"my-ingestion\",\"state\":\"Running\",\"batchName\":\"806945f0-9154-4ba3-b39f-022b693b4e0f\",\"createdDateTime\":\"2024-01-08T12:42:21.4841613Z\",\"lastModifiedDateTime\":\"2024-01-08T12:42:21.7341652Z\"}\n",
      "{'value': [{'name': 'my-ingestion', 'state': 'Completed', 'batchName': '806945f0-9154-4ba3-b39f-022b693b4e0f', 'createdDateTime': '2024-01-08T12:42:21.4841613Z', 'lastModifiedDateTime': '2024-01-08T12:42:47.8591808Z'}]}\n",
      "Ingestion completed.\n"
     ]
    }
   ],
   "source": [
    "# You only need to run this cell once to create the index\n",
    "process_video_indexing(vision_api_endpoint, vision_api_key, video_index_name, video_SAS_url, video_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabcd3f",
   "metadata": {},
   "source": [
    "### Call GPT-4V API with Video Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6165c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The advertisement video is a visual showcase of a digital product, specifically an AI companion app named Copilot, presented by Microsoft.\n",
      "The video uses vibrant and surreal background imagery, such as whimsical landscapes and fantastical flora, to depict various use cases of the app.\n",
      "The color palette is soft and pastel, with predominant shades of blue, pink, and purple, creating a calming and inviting atmosphere.\n",
      "\n",
      "Each frame highlights different features of the app with text prompts such as \"Inspire new ideas,\" \"Research a topic,\" and \"Organize my plans,\" suggesting the app's versatility in assisting with creative, informational, and organizational tasks.\n",
      "The app interface is intermittently displayed, featuring a clean and user-friendly design, with simulated screens hinting at a customizable and interactive experience.\n",
      "Additionally, the video illustrates the dark mode feature, emphasizing comfort and accessibility.\n",
      "\n",
      "There are no human characteristics displayed, as the focus remains solely on the app's capabilities and the immersive environments representing the tasks it can help accomplish.\n",
      "\n",
      "In summary, the advertisement video communicates the main message that Microsoft's Copilot is an everyday AI companion designed to assist users in various aspects of their digital lives, from generating ideas and doing research to planning and relaxation, all within a beautifully designed and intuitive interface.\n"
     ]
    }
   ],
   "source": [
    "# System messages and user prompt\n",
    "sys_message = \"\"\"\n",
    "Your task is to assist in analyzing and optimizing creative assets. \n",
    "You will be presented with advertisement videos for products. \n",
    "First describe the video in detail paying close attention to Product characteristics highlighted, \n",
    "Background images, Lighting, Color Palette and Human characteristics for persons in the video. \n",
    "Finally provide a summary of the video and talk about the main message the advertisement video tries to convey to the viewer. \n",
    "\"\"\"\n",
    "user_prompt = \"Summarize the ad video\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_message}]},\n",
    "    {\"role\": \"user\", \"content\": [{\"type\": \"acv_document_id\", \"acv_document_id\": video_id}]},\n",
    "    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": user_prompt}]},  # Prompt for the user\n",
    "]\n",
    "\n",
    "vision_api_config = {\"endpoint\": vision_api_endpoint, \"key\": vision_api_key}\n",
    "\n",
    "video_config = {\n",
    "    \"video_SAS_url\": video_SAS_url,\n",
    "    \"video_index_name\": video_index_name,\n",
    "}\n",
    "\n",
    "# Call GPT-4V API and print the response\n",
    "try:\n",
    "    response = call_GPT4V_video(messages, vision_api=vision_api_config, video_index=video_config)\n",
    "    text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    sentences = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\", text)\n",
    "    for sentence in sentences:  # Print the content of the response\n",
    "        print(sentence)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to call GPT-4V API. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e4343",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Azure ML resources used in this example, you can delete the individual resources you created in this tutorial.\n",
    "\n",
    "If you made a resource group specifically to run this example, you could instead [delete the resource group](https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/delete-resource-group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb64f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if should_cleanup:\n",
    "    # {{TODO: Add resource cleanup}}\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
