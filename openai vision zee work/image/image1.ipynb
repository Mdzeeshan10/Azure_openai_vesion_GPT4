{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "GPT4V_KEY = \"4660b804230a4cde925f324b813126f3\"\n",
    "IMAGE_PATH = \"images/kill.jpg\"\n",
    "encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": GPT4V_KEY,\n",
    "}\n",
    "\n",
    "# Payload for the request\n",
    "payload = {\n",
    "  \"enhancements\": {\n",
    "    \"ocr\": {\n",
    "      \"enabled\": True\n",
    "    },\n",
    "    \"grounding\": {\n",
    "      \"enabled\": True\n",
    "    }\n",
    "  },\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4V_ENDPOINT = \"https://mohammedzeeshan-aiservices1332475481.openai.azure.com/openai/deployments/gpt-4/extensions/chat/completions?api-version=2023-07-01-preview\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8fguMqIzZRNG2u3ltJX1fzYwJRRlh', 'object': 'chat.completion', 'created': 1704947078, 'model': 'gpt-4', 'choices': [{'finish_details': {'type': 'stop', 'stop': '<|fim_suffix|>'}, 'index': 0, 'message': {'role': 'assistant', 'content': 'Great! How can I assist you today?'}}], 'usage': {'prompt_tokens': 18, 'completion_tokens': 9, 'total_tokens': 27}}\n"
     ]
    }
   ],
   "source": [
    "# Send request\n",
    "try:\n",
    "    response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Handle the response as needed (e.g., print or process)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great! How can I assist you today?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great! How can I assist you today?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "# Configuration\n",
    "GPT4V_KEY = \"YOUR_API_KEY\"\n",
    "IMAGE_PATH = \"YOUR_IMAGE_PATH\"\n",
    "encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": GPT4V_KEY,\n",
    "}\n",
    "\n",
    "# Payload for the request\n",
    "payload = {\n",
    "  \"enhancements\": {\n",
    "    \"ocr\": {\n",
    "      \"enabled\": True\n",
    "    },\n",
    "    \"grounding\": {\n",
    "      \"enabled\": True\n",
    "    }\n",
    "  },\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}\n",
    "\n",
    "GPT4V_ENDPOINT = \"https://mohammedzeeshan-aiservices1332475481.openai.azure.com/openai/deployments/gpt-4/extensions/chat/completions?api-version=2023-07-01-preview\"\n",
    "\n",
    "# Send request\n",
    "try:\n",
    "    response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Handle the response as needed (e.g., print or process)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8knUmK6lXFTlIkEP5tt1EIZrGo9Ee', 'object': 'chat.completion', 'created': 1706164040, 'model': 'gpt-4', 'choices': [{'finish_details': {'type': 'stop', 'stop': '<|fim_suffix|>'}, 'index': 0, 'message': {'role': 'assistant', 'content': 'There is one gun visible in this image, held by the individual on the left.'}, 'enhancements': {'grounding': {'lines': [{'text': 'There is one gun visible in this image, held by the individual on the left.', 'spans': [{'text': 'one gun', 'length': 7, 'offset': 9, 'polygon': [{'x': 0.2915000021457672, 'y': 0.2565000057220459}, {'x': 0.3595000207424164, 'y': 0.2565000057220459}, {'x': 0.3595000207424164, 'y': 0.35249999165534973}, {'x': 0.2915000021457672, 'y': 0.35249999165534973}]}, {'text': 'the individual', 'length': 14, 'offset': 48, 'polygon': [{'x': 0.0885000005364418, 'y': 0.15850000083446503}, {'x': 0.3505000174045563, 'y': 0.15850000083446503}, {'x': 0.3505000174045563, 'y': 0.9445000290870667}, {'x': 0.0885000005364418, 'y': 0.9445000290870667}]}]}], 'status': 'Success'}}}], 'usage': {'prompt_tokens': 1164, 'completion_tokens': 17, 'total_tokens': 1181}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "# Configuration\n",
    "GPT4V_KEY = \"4660b804230a4cde925f324b813126f3\"\n",
    "IMAGE_PATH = \"images/kill.jpg\"\n",
    "encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": GPT4V_KEY,\n",
    "}\n",
    "\n",
    "# Payload for the request\n",
    "payload = {\n",
    "  \"enhancements\": {\n",
    "    \"ocr\": {\n",
    "      \"enabled\": True\n",
    "    },\n",
    "    \"grounding\": {\n",
    "      \"enabled\": True\n",
    "    }\n",
    "  },\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"how many gun in this.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}\n",
    "\n",
    "GPT4V_ENDPOINT = \"https://mohammedzeeshan-aiservices1332475481.openai.azure.com/openai/deployments/gpt-4/extensions/chat/completions?api-version=2023-07-01-preview\"\n",
    "\n",
    "# Send request\n",
    "try:\n",
    "    response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Handle the response as needed (e.g., print or process)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is one gun visible in this image, held by the individual on the left.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8knW09J6LH5Zz7SAfdDKQ89NLARuQ', 'object': 'chat.completion', 'created': 1706164116, 'model': 'gpt-4', 'choices': [{'finish_details': {'type': 'stop', 'stop': '<|fim_suffix|>'}, 'index': 0, 'message': {'role': 'assistant', 'content': 'There is one person visible in this image.'}, 'enhancements': {'grounding': {'lines': [{'text': 'There is one person visible in this image.', 'spans': [{'text': 'one person', 'length': 10, 'offset': 9, 'polygon': [{'x': 0.08750000596046448, 'y': 0.15450000762939453}, {'x': 0.3505000174045563, 'y': 0.15450000762939453}, {'x': 0.3505000174045563, 'y': 0.9415000081062317}, {'x': 0.08750000596046448, 'y': 0.9415000081062317}]}, {'text': 'one person', 'length': 10, 'offset': 9, 'polygon': [{'x': 0.5394999980926514, 'y': 0.21650001406669617}, {'x': 0.7125000357627869, 'y': 0.21650001406669617}, {'x': 0.7125000357627869, 'y': 0.9104999899864197}, {'x': 0.5394999980926514, 'y': 0.9104999899864197}]}]}], 'status': 'Success'}}}], 'usage': {'prompt_tokens': 1164, 'completion_tokens': 9, 'total_tokens': 1173}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "# Configuration\n",
    "GPT4V_KEY = \"4660b804230a4cde925f324b813126f3\"\n",
    "IMAGE_PATH = \"images/kill.jpg\"\n",
    "encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": GPT4V_KEY,\n",
    "}\n",
    "\n",
    "# Payload for the request\n",
    "payload = {\n",
    "  \"enhancements\": {\n",
    "    \"ocr\": {\n",
    "      \"enabled\": True\n",
    "    },\n",
    "    \"grounding\": {\n",
    "      \"enabled\": True\n",
    "    }\n",
    "  },\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"how many people in this.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}\n",
    "\n",
    "GPT4V_ENDPOINT = \"https://mohammedzeeshan-aiservices1332475481.openai.azure.com/openai/deployments/gpt-4/extensions/chat/completions?api-version=2023-07-01-preview\"\n",
    "\n",
    "# Send request\n",
    "try:\n",
    "    response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Handle the response as needed (e.g., print or process)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is one person visible in this image.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"images/kill.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_gpt4v(query):\n",
    "    import os\n",
    "    import requests\n",
    "    import base64\n",
    "\n",
    "    # Configuration\n",
    "    GPT4V_KEY = \"4660b804230a4cde925f324b813126f3\"\n",
    "    IMAGE_PATH = img_path\n",
    "    encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": GPT4V_KEY,\n",
    "    }\n",
    "\n",
    "    # Payload for the request\n",
    "    payload = {\n",
    "      \"enhancements\": {\n",
    "        \"ocr\": {\n",
    "          \"enabled\": True\n",
    "        },\n",
    "        \"grounding\": {\n",
    "          \"enabled\": True\n",
    "        }\n",
    "      },\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": query\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"temperature\": 0.7,\n",
    "      \"top_p\": 0.95,\n",
    "      \"max_tokens\": 800\n",
    "    }\n",
    "\n",
    "    GPT4V_ENDPOINT = \"https://mohammedzeeshan-aiservices1332475481.openai.azure.com/openai/deployments/gpt-4/extensions/chat/completions?api-version=2023-07-01-preview\"\n",
    "\n",
    "    # Send request\n",
    "    try:\n",
    "        response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "    except requests.RequestException as e:\n",
    "        raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "    # Handle the response as needed (e.g., print or process)\n",
    "    return response.json()['choices'][0]['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There appears to be one house visible in the background of the image.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how many house in this.\"\n",
    "image_gpt4v(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_gpt4v_fun import image_gpt4v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "\n",
    "while i < 10:\n",
    "    query = str(input(\"Enter your quer : \"))\n",
    "    image_gpt4v(query)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helo\n",
      "helo\n",
      "helo\n",
      "helo\n",
      "helo\n",
      "helo\n",
      "helo\n",
      "helo\n",
      "helo\n",
      "helo\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "\n",
    "while i < 10:\n",
    "    print(\"helo\")\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
